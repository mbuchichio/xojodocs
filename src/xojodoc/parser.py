"""HTML parser for Xojo documentation.

Extracts class information from HTML files generated by Sphinx.
"""

from pathlib import Path
from typing import Optional, List, Tuple
from bs4 import BeautifulSoup, Tag
from .database import XojoClass, XojoProperty, XojoMethod


class HTMLParser:
    """Parses Xojo documentation HTML files."""

    def __init__(self, html_root: str = "html"):
        """Initialize parser.
        
        Args:
            html_root: Root directory containing HTML documentation
        """
        self.html_root = Path(html_root)
        self.api_root = self.html_root / "api"
        
    def discover_classes(self) -> List[Tuple[str, str]]:
        """Discover all class HTML files.
        
        Returns:
            List of (module, file_path) tuples
        """
        classes = []
        
        if not self.api_root.exists():
            raise FileNotFoundError(f"API root not found: {self.api_root}")
            
        # Walk through api directory
        for module_dir in self.api_root.iterdir():
            if not module_dir.is_dir():
                continue
                
            module_name = module_dir.name
            
            # Find all HTML files except index.html
            for html_file in module_dir.glob("*.html"):
                if html_file.name == "index.html":
                    continue
                    
                classes.append((module_name, str(html_file)))
                
        return classes
        
    def parse_class_file(self, file_path: str) -> Optional[XojoClass]:
        """Parse a single class HTML file.
        
        Args:
            file_path: Path to HTML file
            
        Returns:
            XojoClass object or None if parsing fails
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                soup = BeautifulSoup(f.read(), 'lxml')
                
            # Extract class name from h1
            h1 = soup.find('h1')
            if not h1:
                return None
                
            class_name = h1.get_text().strip()
            
            # Extract module from file path
            path = Path(file_path)
            module = path.parent.name
            
            # Extract description
            description_section = soup.find('section', id='description')
            description = None
            if description_section:
                # Get all paragraphs in description, excluding admonitions
                paragraphs = description_section.find_all('p', recursive=False)
                if paragraphs:
                    description = '\n'.join(p.get_text().strip() for p in paragraphs)
                    
            # Extract sample code
            sample_code = self._extract_sample_code(soup)
            
            # Extract compatibility
            compatibility = self._extract_compatibility(soup)
            
            # Extract notes
            notes = self._extract_notes(soup)
            
            return XojoClass(
                name=class_name,
                module=module,
                description=description,
                sample_code=sample_code,
                compatibility=compatibility,
                notes=notes,
                file_path=file_path
            )
            
        except Exception as e:
            print(f"Error parsing {file_path}: {e}")
            return None
            
    def parse_properties(self, file_path: str) -> List[XojoProperty]:
        """Parse properties from a class HTML file.
        
        Args:
            file_path: Path to HTML file
            
        Returns:
            List of XojoProperty objects
        """
        properties = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                soup = BeautifulSoup(f.read(), 'lxml')
                
            # Find properties table
            properties_section = soup.find('section', id='properties')
            if not properties_section:
                return properties
                
            table = properties_section.find('table')
            if not table:
                return properties
                
            tbody = table.find('tbody')
            if not tbody:
                return properties
                
            # Parse each row
            for row in tbody.find_all('tr'):
                cells = row.find_all('td')
                if len(cells) < 4:
                    continue
                    
                # Extract property name from link
                name_link = cells[0].find('a')
                if not name_link:
                    continue
                prop_name = name_link.get_text().strip()
                prop_anchor = name_link.get('href', '').lstrip('#')
                
                # Extract type
                type_link = cells[1].find('a')
                prop_type = type_link.get_text().strip() if type_link else cells[1].get_text().strip()
                
                # Check read-only
                read_only = '✓' in cells[2].get_text()
                
                # Check shared
                shared = '✓' in cells[3].get_text()
                
                # Extract detailed description
                description = self._extract_property_description(soup, prop_anchor)
                
                properties.append(XojoProperty(
                    name=prop_name,
                    type=prop_type,
                    read_only=read_only,
                    shared=shared,
                    description=description
                ))
                
        except Exception as e:
            print(f"Error parsing properties from {file_path}: {e}")
            
        return properties
        
    def parse_methods(self, file_path: str) -> List[XojoMethod]:
        """Parse methods from a class HTML file.
        
        Args:
            file_path: Path to HTML file
            
        Returns:
            List of XojoMethod objects
        """
        methods = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                soup = BeautifulSoup(f.read(), 'lxml')
                
            # Find methods table
            methods_section = soup.find('section', id='methods')
            if not methods_section:
                return methods
                
            table = methods_section.find('table')
            if not table:
                return methods
                
            tbody = table.find('tbody')
            if not tbody:
                return methods
                
            # Parse each row
            for row in tbody.find_all('tr'):
                cells = row.find_all('td')
                if len(cells) < 4:
                    continue
                    
                # Extract method name
                name_link = cells[0].find('a')
                if not name_link:
                    continue
                method_name = name_link.get_text().strip()
                method_anchor = name_link.get('href', '').lstrip('#')
                
                # Extract parameters
                parameters = cells[1].get_text().strip() or None
                
                # Extract return type
                return_type_link = cells[2].find('a')
                return_type = return_type_link.get_text().strip() if return_type_link else cells[2].get_text().strip()
                return_type = return_type if return_type else None
                
                # Check shared
                shared = '✓' in cells[3].get_text()
                
                # Extract detailed description and sample code
                description, sample_code = self._extract_method_description(soup, method_anchor)
                
                methods.append(XojoMethod(
                    name=method_name,
                    parameters=parameters,
                    return_type=return_type,
                    shared=shared,
                    description=description,
                    sample_code=sample_code
                ))
                
        except Exception as e:
            print(f"Error parsing methods from {file_path}: {e}")
            
        return methods
        
    def _extract_sample_code(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract sample code from sample-code section."""
        sample_section = soup.find('section', id='sample-code')
        if not sample_section:
            return None
            
        code_blocks = sample_section.find_all('div', class_='highlight-xojo')
        if not code_blocks:
            return None
            
        codes = []
        for block in code_blocks:
            pre = block.find('pre')
            if pre:
                codes.append(pre.get_text().strip())
                
        return '\n\n'.join(codes) if codes else None
        
    def _extract_compatibility(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract compatibility information."""
        compat_section = soup.find('section', id='compatibility')
        if not compat_section:
            return None
            
        paragraphs = compat_section.find_all('p')
        if paragraphs:
            return paragraphs[0].get_text().strip()
            
        return None
        
    def _extract_notes(self, soup: BeautifulSoup) -> Optional[str]:
        """Extract notes section."""
        notes_section = soup.find('section', id='notes')
        if not notes_section:
            return None
            
        # Get all text from notes section
        text_parts = []
        for elem in notes_section.find_all(['p', 'h3', 'h4']):
            text_parts.append(elem.get_text().strip())
            
        return '\n\n'.join(text_parts) if text_parts else None
        
    def _extract_property_description(self, soup: BeautifulSoup, anchor: str) -> Optional[str]:
        """Extract detailed property description."""
        if not anchor:
            return None
            
        prop_section = soup.find('section', id=anchor)
        if not prop_section:
            return None
            
        # Skip the h3 and signature, get description paragraphs
        paragraphs = []
        for elem in prop_section.find_all('p'):
            text = elem.get_text().strip()
            # Skip signature lines (they often start with property name)
            if not text.startswith(anchor.split('-')[-1]):
                paragraphs.append(text)
                
        return '\n\n'.join(paragraphs) if paragraphs else None
        
    def _extract_method_description(self, soup: BeautifulSoup, anchor: str) -> Tuple[Optional[str], Optional[str]]:
        """Extract detailed method description and sample code."""
        if not anchor:
            return None, None
            
        method_section = soup.find('section', id=anchor)
        if not method_section:
            return None, None
            
        # Extract description
        paragraphs = []
        for elem in method_section.find_all('p', recursive=False):
            text = elem.get_text().strip()
            # Skip signature lines
            if '(' in text and ')' in text and text.count('(') == 1:
                continue
            paragraphs.append(text)
            
        description = '\n\n'.join(paragraphs) if paragraphs else None
        
        # Extract sample code
        code_blocks = method_section.find_all('div', class_='highlight-xojo')
        codes = []
        for block in code_blocks:
            pre = block.find('pre')
            if pre:
                codes.append(pre.get_text().strip())
                
        sample_code = '\n\n'.join(codes) if codes else None
        
        return description, sample_code
